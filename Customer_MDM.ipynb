{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4cDoHgwcLcv70j5C8HDvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamsonOluwaseun/All_About_Analytics/blob/main/Customer_MDM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_GvBFjhWSF-2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define the current date as a reference for CreationDate simulation\n",
        "current_date = datetime.now().date()\n",
        "np.random.seed(42) # for reproducibility\n",
        "\n",
        "# --- Helper function to generate simulated records (Modified for ID format) ---\n",
        "def generate_customer_records_complex(num_records, source_id_type):\n",
        "    \"\"\"Generates complex simulated customer records, tailoring the ID format to the source.\"\"\"\n",
        "    records = []\n",
        "\n",
        "    # Base list of common customers (to ensure deliberate matches and duplicates) - Unchanged PII Data\n",
        "    base_customers = [\n",
        "        ('John', 'Smith', '1985-05-15', '123 Main St, Anytown', 'M', '555-1001'),\n",
        "        ('Jon', 'Smith', '1985-05-15', '123 Main Street', 'Male', '5551001'),\n",
        "        ('J. J.', 'Smyth', '1985-05-15', '123 Main St Apt 2B', '1', '5551001'),\n",
        "        ('Jane', 'Doe', '1990-11-20', '45 Oak Ave, City', 'F', '555-2002'),\n",
        "        ('Jaine', 'Doh', '1990-11-20', '45 Oak Avenue', 'Female', '5552002'),\n",
        "        ('Peter', 'Jones', '1975-02-01', '789 Pine Ln', 'MALE', '555-3003'),\n",
        "        ('P.', 'Jones', '1975-02-01', '789 Pine Lane', 'M', '555-3003'),\n",
        "        ('Mary', 'Williams', '1988-08-08', '33 River Rd', 'F', '555-4004'),\n",
        "        ('Alice', 'Brown', '1995-01-01', '50 High St', 'F', '555-5005'),\n",
        "        ('Robert', 'White', '1970-12-25', '10 Elm Dr', 'M', '555-6006'),\n",
        "        ('Chris', 'Green', '2000-03-10', '90 Park Ave', 'M', '555-7007'),\n",
        "    ]\n",
        "\n",
        "    # Pad the base list to ensure we reach num_records\n",
        "    while len(base_customers) < num_records:\n",
        "        base_customers.append((\n",
        "            np.random.choice(['David', 'Laura', 'Mark', 'Sarah']),\n",
        "            np.random.choice(['Taylor', 'Clark', 'Hall', 'Baker']),\n",
        "            (current_date - timedelta(days=np.random.randint(7000, 20000))).strftime('%Y-%m-%d'),\n",
        "            f'{np.random.randint(10, 999)} Random Road',\n",
        "            np.random.choice(['M', 'F']),\n",
        "            f'555-{np.random.randint(1000, 9999)}'\n",
        "        ))\n",
        "\n",
        "\n",
        "    records_list = []\n",
        "    for i in range(num_records):\n",
        "        base_idx = i % len(base_customers)\n",
        "        first_name, last_name, dob, address, sex, phone = base_customers[base_idx]\n",
        "        creation_date = (current_date - timedelta(days=np.random.randint(30, 1000))).strftime('%Y-%m-%d')\n",
        "\n",
        "        # --- ID FORMAT LOGIC ---\n",
        "        if source_id_type == 'S1_Policy_ID':\n",
        "            # 1. Full Integer (e.g., 100100, 100101, ...)\n",
        "            source_id = 100000 + i\n",
        "        elif source_id_type == 'S2_Claimant_ID':\n",
        "            # 2. Alpha-Numeric 5-digit (e.g., CL-001, CL-002, ...)\n",
        "            source_id = f'CL-{i+1:03d}'\n",
        "        elif source_id_type == 'S3_CRM_ID':\n",
        "            # 3. Alpha-Numeric 8-digit (e.g., CUST-1000, CUST-1001, ...)\n",
        "            source_id = f'CUST-{1000 + i}'\n",
        "        else:\n",
        "             source_id = i + 1000 # Fallback\n",
        "        # -----------------------\n",
        "\n",
        "        record = {\n",
        "            f'{source_id_type}': source_id,\n",
        "            'First_Name': first_name,\n",
        "            'Last_Name': last_name,\n",
        "            'DOB': dob,\n",
        "            'Sex': sex,\n",
        "            'Address_Line': address,\n",
        "            'Creation_Timestamp': creation_date,\n",
        "            'Phone_Number': phone\n",
        "        }\n",
        "        records_list.append(record)\n",
        "\n",
        "    return pd.DataFrame(records_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================\n",
        "# --- 2. Create Table According to Sources (20 Records Each with Varied IDs) ---\n",
        "# ====================================================================================\n",
        "\n",
        "# S1: Life Insurance Policy Admin (Legacy) - Full Integer ID\n",
        "df_s1_raw = generate_customer_records_complex(20, 'S1_Policy_ID').rename(columns={\n",
        "    'First_Name': 'Cust_FName', 'Last_Name': 'Cust_LName', 'DOB': 'Birth_Date',\n",
        "    'Sex': 'Gender_Code', 'Address_Line': 'Policy_Address',\n",
        "    'Creation_Timestamp': 'S1_Creation_DTS', 'Phone_Number': 'Phone'\n",
        "})\n",
        "df_s1_raw['SourceSystem'] = 'S1_Life'\n",
        "df_s1_raw['S1_Policy_ID'] = df_s1_raw['S1_Policy_ID'].astype(int) # Ensure S1 ID is integer\n",
        "\n",
        "# S2: Auto Insurance Claims System - 5-digit Alpha-Numeric ID\n",
        "df_s2_raw = generate_customer_records_complex(20, 'S2_Claimant_ID').rename(columns={\n",
        "    'First_Name': 'FName', 'Last_Name': 'LName', 'DOB': 'DOB',\n",
        "    'Sex': 'Sex', 'Address_Line': 'Claimant_Addr',\n",
        "    'Creation_Timestamp': 'Rec_Create_Dt', 'Phone_Number': 'Claim_Phone'\n",
        "})\n",
        "# S2 internal duplicate to test matching robustness\n",
        "df_s2_raw.loc[0, 'FName'] = 'John'\n",
        "df_s2_raw.loc[1, 'FName'] = 'John'\n",
        "df_s2_raw['SourceSystem'] = 'S2_Claims'\n",
        "\n",
        "\n",
        "# S3: CRM System (Modern) - 8-digit Alpha-Numeric ID\n",
        "df_s3_raw = generate_customer_records_complex(20, 'S3_CRM_ID').rename(columns={\n",
        "    'First_Name': 'Customer_First', 'Last_Name': 'Customer_Last', 'DOB': 'Date_Of_Birth',\n",
        "    'Sex': 'Sex', 'Address_Line': 'Primary_Address',\n",
        "    'Creation_Timestamp': 'CRM_Record_Date', 'Phone_Number': 'Contact_Phone'\n",
        "})\n",
        "# S3 data quality formatting\n",
        "df_s3_raw.loc[df_s3_raw['Sex'] == 'M', 'Sex'] = 'Male'\n",
        "df_s3_raw.loc[df_s3_raw['Sex'] == 'F', 'Sex'] = 'Female'\n",
        "df_s3_raw['SourceSystem'] = 'S3_CRM'\n",
        "\n",
        "print(\"--- Source DataFrames with Distinct ID Formats ---\")\n",
        "print(f\"S1_Life ID Example: {df_s1_raw['S1_Policy_ID'].iloc[0]} (Type: {df_s1_raw['S1_Policy_ID'].dtype})\")\n",
        "print(f\"S2_Claims ID Example: {df_s2_raw['S2_Claimant_ID'].iloc[0]} (Type: {df_s2_raw['S2_Claimant_ID'].dtype})\")\n",
        "print(f\"S3_CRM ID Example: {df_s3_raw['S3_CRM_ID'].iloc[0]} (Type: {df_s3_raw['S3_CRM_ID'].dtype})\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# CONSOLIDATION: Combine all source tables into the Staging Area\n",
        "raw_df = pd.concat([df_s1_raw, df_s2_raw, df_s3_raw], ignore_index=True)\n",
        "raw_df.index.name = 'Raw_Record_ID'\n",
        "\n",
        "print(f\"\\n--- Consolidated Raw Data (Staging Area) - Total {len(raw_df)} Records ---\")\n",
        "# Display the different ID formats\n",
        "print(raw_df[['SourceSystem', 'S1_Policy_ID', 'S2_Claimant_ID', 'S3_CRM_ID',\n",
        "              'Cust_FName', 'FName', 'Customer_First', 'S1_Creation_DTS']].head(10).fillna('-'))\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cd--fZISKi1",
        "outputId": "ec3e9614-ddd0-4b8d-98ff-43b9717b560c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Source DataFrames with Distinct ID Formats ---\n",
            "S1_Life ID Example: 100000 (Type: int64)\n",
            "S2_Claims ID Example: CL-001 (Type: object)\n",
            "S3_CRM ID Example: CUST-1000 (Type: object)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "--- Consolidated Raw Data (Staging Area) - Total 60 Records ---\n",
            "              SourceSystem  S1_Policy_ID S2_Claimant_ID S3_CRM_ID Cust_FName  \\\n",
            "Raw_Record_ID                                                                  \n",
            "0                  S1_Life      100000.0              -         -       John   \n",
            "1                  S1_Life      100001.0              -         -        Jon   \n",
            "2                  S1_Life      100002.0              -         -      J. J.   \n",
            "3                  S1_Life      100003.0              -         -       Jane   \n",
            "4                  S1_Life      100004.0              -         -      Jaine   \n",
            "5                  S1_Life      100005.0              -         -      Peter   \n",
            "6                  S1_Life      100006.0              -         -         P.   \n",
            "7                  S1_Life      100007.0              -         -       Mary   \n",
            "8                  S1_Life      100008.0              -         -      Alice   \n",
            "9                  S1_Life      100009.0              -         -     Robert   \n",
            "\n",
            "              FName Customer_First S1_Creation_DTS  \n",
            "Raw_Record_ID                                       \n",
            "0                 -              -      2023-12-18  \n",
            "1                 -              -      2025-09-04  \n",
            "2                 -              -      2023-06-07  \n",
            "3                 -              -      2025-04-11  \n",
            "4                 -              -      2024-12-25  \n",
            "5                 -              -      2024-09-02  \n",
            "6                 -              -      2024-02-02  \n",
            "7                 -              -      2024-11-13  \n",
            "8                 -              -      2025-09-11  \n",
            "9                 -              -      2025-01-26  \n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================\n",
        "# --- 3. Table Transformation and Consolidation Script (Rule-Based Standardization) ---\n",
        "# ====================================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define the canonical column names for the MDM Hub\n",
        "CANONICAL_COLUMNS = {\n",
        "    'First_Name': ['Cust_FName', 'FName', 'Customer_First'],\n",
        "    'Last_Name': ['Cust_LName', 'LName', 'Customer_Last'],\n",
        "    'DOB': ['Birth_Date', 'DOB', 'Date_Of_Birth'],\n",
        "    'Sex': ['Gender_Code', 'Sex'],\n",
        "    'Address': ['Policy_Address', 'Claimant_Addr', 'Primary_Address'],\n",
        "    'Phone': ['Phone', 'Claim_Phone', 'Contact_Phone'],\n",
        "    'CreationDate': ['S1_Creation_DTS', 'Rec_Create_Dt', 'CRM_Record_Date']\n",
        "}\n",
        "\n",
        "def standardize_data(df, canonical_map):\n",
        "    \"\"\"\n",
        "    Performs data mapping, standardization, and cleans data into a canonical model.\n",
        "    Uses basic cleansing combined with recency-based rules for First/Last Name.\n",
        "    \"\"\"\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    # 1. MAP DISPARATE COLUMNS TO CANONICAL NAMES\n",
        "    for canonical, source_list in canonical_map.items():\n",
        "        df_clean[canonical] = df_clean.apply(\n",
        "            lambda row: next((row[col] for col in source_list if col in row and pd.notna(row[col])), None),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Ensure Dates are ready for sorting\n",
        "    df_clean['DOB'] = pd.to_datetime(df_clean['DOB'], errors='coerce').dt.date\n",
        "    df_clean['CreationDate'] = pd.to_datetime(df_clean['CreationDate'], errors='coerce')\n",
        "\n",
        "    # 2. STANDARDIZATION AND CLEANSING (Canonical Fields)\n",
        "\n",
        "    # A. Initial Cleanse (Standardize format before applying rules)\n",
        "    # This addresses obvious, non-semantic variations like casing or initials.\n",
        "    df_clean['FirstName_C'] = df_clean['First_Name'].astype(str).str.strip().str.upper().str.replace('.', '', regex=False)\n",
        "    df_clean['LastName_C'] = df_clean['Last_Name'].astype(str).str.strip().str.upper()\n",
        "\n",
        "    # B. Rule-Based Name Standardization (Recency Rule)\n",
        "    # We will prioritize the longest, most recent name for groups of potential matches.\n",
        "    # Since we don't have the final match groups yet (that's Step 4), we apply the rule\n",
        "    # *conditionally* on records that share key PII (DOB, Last Name) that is typically stable.\n",
        "\n",
        "    # 1. Group records that are highly likely to be the same person\n",
        "    group_cols = ['LastName_C', 'DOB']\n",
        "\n",
        "    # 2. Within each group, determine the \"best\" FirstName and LastName using a complex rule:\n",
        "    #    Rule: MAX(Recency) then MAX(Length)\n",
        "    def determine_best_name(group, name_col):\n",
        "        # Sort by CreationDate (Most Recent first), then by name length (Longest first)\n",
        "        group_sorted = group.sort_values(by=['CreationDate', name_col], ascending=[False, False])\n",
        "\n",
        "        # Return the value from the top record\n",
        "        return group_sorted[name_col].iloc[0]\n",
        "\n",
        "    # Apply the rule to create the final standardized columns (_S)\n",
        "    df_clean['FirstName_S'] = df_clean.groupby(group_cols, dropna=False)['FirstName_C'].transform(\n",
        "        lambda x: determine_best_name(df_clean.loc[x.index], 'FirstName_C')\n",
        "    )\n",
        "\n",
        "    df_clean['LastName_S'] = df_clean.groupby(group_cols, dropna=False)['LastName_C'].transform(\n",
        "        lambda x: determine_best_name(df_clean.loc[x.index], 'LastName_C')\n",
        "    )\n",
        "\n",
        "    # C. Other Standardizations (As before)\n",
        "    df_clean['Sex_S'] = df_clean['Sex'].astype(str).str.upper().replace({'M': 'MALE', '1': 'MALE', 'F': 'FEMALE', '2': 'FEMALE'}, regex=False)\n",
        "\n",
        "    df_clean['Phone_S'] = df_clean['Phone'].astype(str).str.replace(r'[^0-9]', '', regex=True)\n",
        "    df_clean['Phone_S'] = df_clean.apply(\n",
        "        lambda row: f'{row[\"Phone_S\"][:3]}-{row[\"Phone_S\"][3:6]}-{row[\"Phone_S\"][6:10]}'\n",
        "        if len(row[\"Phone_S\"]) == 10 else None, axis=1\n",
        "    )\n",
        "    df_clean['Address_S'] = df_clean['Address'].astype(str).str.upper().str.replace(' AVENUE', ' AVE', regex=False).str.replace(' ROAD', ' RD', regex=False).str.strip()\n",
        "\n",
        "    # 3. SELECT FINAL STAGING COLUMNS\n",
        "    cols_to_keep = ['Raw_Record_ID', 'SourceSystem', 'S1_Policy_ID', 'S2_Claimant_ID', 'S3_CRM_ID', 'CreationDate']\n",
        "    cols_to_keep.extend(['FirstName_S', 'LastName_S', 'DOB', 'Sex_S', 'Address_S', 'Phone_S'])\n",
        "\n",
        "    return df_clean[cols_to_keep]\n",
        "\n",
        "# --- Note: You must run the data generation (Step 2) before running this ---\n",
        "\n",
        "# Assuming 'raw_df' exists from Step 2 and needs the index reset fix:\n",
        "# The Raw_Record_ID is currently the DataFrame index. Resetting it converts it into a regular column.\n",
        "raw_df = raw_df.reset_index() # Uncomment this line if running in sequence\n",
        "\n",
        "staged_df = standardize_data(raw_df, CANONICAL_COLUMNS)\n",
        "\n",
        "# print(\"--- Staged Data (Canonical Model Ready for Matching) - First 8 Records ---\")\n",
        "print(staged_df[['SourceSystem', 'S1_Policy_ID', 'S2_Claimant_ID', 'S3_CRM_ID', 'FirstName_S', 'LastName_S', 'CreationDate']].head(8).fillna('-'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65W08SjLSYBk",
        "outputId": "cc66c780-fc7a-442e-bb59-782c1c020b46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  SourceSystem  S1_Policy_ID S2_Claimant_ID S3_CRM_ID FirstName_S LastName_S  \\\n",
            "0      S1_Life      100000.0              -         -         JON      SMITH   \n",
            "1      S1_Life      100001.0              -         -         JON      SMITH   \n",
            "2      S1_Life      100002.0              -         -         J J      SMYTH   \n",
            "3      S1_Life      100003.0              -         -        JANE        DOE   \n",
            "4      S1_Life      100004.0              -         -       JAINE        DOH   \n",
            "5      S1_Life      100005.0              -         -       PETER      JONES   \n",
            "6      S1_Life      100006.0              -         -       PETER      JONES   \n",
            "7      S1_Life      100007.0              -         -        MARY   WILLIAMS   \n",
            "\n",
            "  CreationDate  \n",
            "0   2023-12-18  \n",
            "1   2025-09-04  \n",
            "2   2023-06-07  \n",
            "3   2025-04-11  \n",
            "4   2024-12-25  \n",
            "5   2024-09-02  \n",
            "6   2024-02-02  \n",
            "7   2024-11-13  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Python Script for Matching Rules to Create a Master Record with Master ID ---\n",
        "\n",
        "def perform_matching_and_mastering(staged_df):\n",
        "    \"\"\"Applies matching rules to link records and create a Master ID.\"\"\"\n",
        "\n",
        "    # Initialize Master_ID column\n",
        "    staged_df['Master_ID'] = None\n",
        "    next_master_id = 1\n",
        "\n",
        "    # Matching Logic: Prioritized Rules\n",
        "\n",
        "    # 1. EXACT Match Rule: Full Name + DOB + Phone\n",
        "    match_cols_exact = ['FirstName_S', 'LastName_S', 'DOB', 'Phone_S']\n",
        "    exact_matches = staged_df.dropna(subset=match_cols_exact).groupby(match_cols_exact)\n",
        "\n",
        "    for _, group in exact_matches:\n",
        "        if len(group) > 1:\n",
        "            # If a match is found, use the lowest existing Master_ID or create a new one\n",
        "            existing_mid = group['Master_ID'].dropna().min()\n",
        "            new_mid = existing_mid if pd.notna(existing_mid) else f'CMD_{next_master_id:03d}'\n",
        "            staged_df.loc[group.index, 'Master_ID'] = new_mid\n",
        "            if pd.isna(existing_mid):\n",
        "                next_master_id += 1\n",
        "\n",
        "    # 2. FUZZY Match Rule (Secondary): Full Name + DOB (Ignore Phone/Address variations)\n",
        "    match_cols_fuzzy = ['FirstName_S', 'LastName_S', 'DOB']\n",
        "    fuzzy_matches = staged_df.dropna(subset=match_cols_fuzzy).groupby(match_cols_fuzzy)\n",
        "\n",
        "    for _, group in fuzzy_matches:\n",
        "        if len(group) > 1:\n",
        "            # If a match is found and not yet assigned a Master_ID\n",
        "            unassigned_indices = group[group['Master_ID'].isna()].index\n",
        "\n",
        "            # Use the lowest existing Master_ID from the group, or create a new one\n",
        "            existing_mid = group['Master_ID'].dropna().min()\n",
        "            new_mid = existing_mid if pd.notna(existing_mid) else f'CMD_{next_master_id:03d}'\n",
        "\n",
        "            staged_df.loc[group.index, 'Master_ID'] = new_mid\n",
        "            if pd.isna(existing_mid) and len(unassigned_indices) > 0:\n",
        "                next_master_id += 1\n",
        "\n",
        "    # 3. Handle Remaining Records (Singletons)\n",
        "    unassigned_indices = staged_df[staged_df['Master_ID'].isna()].index\n",
        "    for idx in unassigned_indices:\n",
        "        staged_df.loc[idx, 'Master_ID'] = f'CMD_{next_master_id:03d}'\n",
        "        next_master_id += 1\n",
        "\n",
        "    # --- Survivorship (For Registry Style - Consolidate IDs) ---\n",
        "    # Group all records by the final Master_ID to consolidate source IDs\n",
        "    master_records = staged_df.groupby('Master_ID').agg(\n",
        "        S1_ID=('S1_Policy_ID', lambda x: x.dropna().unique().tolist()),\n",
        "        S2_ID=('S2_Claimant_ID', lambda x: x.dropna().unique().tolist()),\n",
        "        S3_ID=('S3_CRM_ID', lambda x: x.dropna().unique().tolist()),\n",
        "    ).reset_index()\n",
        "\n",
        "    # Simplify the lists to just the first ID for demo, or keep as list\n",
        "    master_records['S1_ID'] = master_records['S1_ID'].apply(lambda x: x[0] if x else None)\n",
        "    master_records['S2_ID'] = master_records['S2_ID'].apply(lambda x: x[0] if x else None)\n",
        "    master_records['S3_ID'] = master_records['S3_ID'].apply(lambda x: x[0] if x else None)\n",
        "\n",
        "    # For a Registry Style, the final table only needs the mapping\n",
        "    mapping_df = staged_df[['Master_ID', 'S1_Policy_ID', 'S2_Claimant_ID', 'S3_CRM_ID']].copy()\n",
        "\n",
        "    return mapping_df.drop_duplicates(subset=['Master_ID']), master_records\n",
        "\n",
        "mapping_df, master_records = perform_matching_and_mastering(staged_df)"
      ],
      "metadata": {
        "id": "qwbLhRSBTc4H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(staged_df.head(10).fillna('-') )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOwLfvc4UlmN",
        "outputId": "e8378aba-959d-46cc-c03a-07aa66997e06"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Raw_Record_ID SourceSystem  S1_Policy_ID S2_Claimant_ID S3_CRM_ID  \\\n",
            "0              0      S1_Life      100000.0              -         -   \n",
            "1              1      S1_Life      100001.0              -         -   \n",
            "2              2      S1_Life      100002.0              -         -   \n",
            "3              3      S1_Life      100003.0              -         -   \n",
            "4              4      S1_Life      100004.0              -         -   \n",
            "5              5      S1_Life      100005.0              -         -   \n",
            "6              6      S1_Life      100006.0              -         -   \n",
            "7              7      S1_Life      100007.0              -         -   \n",
            "8              8      S1_Life      100008.0              -         -   \n",
            "9              9      S1_Life      100009.0              -         -   \n",
            "\n",
            "  CreationDate FirstName_S LastName_S         DOB   Sex_S  \\\n",
            "0   2023-12-18         JON      SMITH  1985-05-15    MALE   \n",
            "1   2025-09-04         JON      SMITH  1985-05-15    MALE   \n",
            "2   2023-06-07         J J      SMYTH  1985-05-15    MALE   \n",
            "3   2025-04-11        JANE        DOE  1990-11-20  FEMALE   \n",
            "4   2024-12-25       JAINE        DOH  1990-11-20  FEMALE   \n",
            "5   2024-09-02       PETER      JONES  1975-02-01    MALE   \n",
            "6   2024-02-02       PETER      JONES  1975-02-01    MALE   \n",
            "7   2024-11-13        MARY   WILLIAMS  1988-08-08  FEMALE   \n",
            "8   2025-09-11       ALICE      BROWN  1995-01-01  FEMALE   \n",
            "9   2025-01-26      ROBERT      WHITE  1970-12-25    MALE   \n",
            "\n",
            "              Address_S Phone_S Master_ID  \n",
            "0  123 MAIN ST, ANYTOWN       -   CMD_006  \n",
            "1       123 MAIN STREET       -   CMD_006  \n",
            "2    123 MAIN ST APT 2B       -   CMD_003  \n",
            "3      45 OAK AVE, CITY       -   CMD_005  \n",
            "4            45 OAK AVE       -   CMD_004  \n",
            "5           789 PINE LN       -   CMD_008  \n",
            "6         789 PINE LANE       -   CMD_008  \n",
            "7           33 RIVER RD       -   CMD_007  \n",
            "8            50 HIGH ST       -   CMD_001  \n",
            "9             10 ELM DR       -   CMD_009  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mapping_df.head(10).fillna('-') )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5DsF_A1UZcM",
        "outputId": "a20db702-181d-4c45-e5ff-14f26d653e3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Master_ID  S1_Policy_ID S2_Claimant_ID S3_CRM_ID\n",
            "0    CMD_006      100000.0              -         -\n",
            "2    CMD_003      100002.0              -         -\n",
            "3    CMD_005      100003.0              -         -\n",
            "4    CMD_004      100004.0              -         -\n",
            "5    CMD_008      100005.0              -         -\n",
            "7    CMD_007      100007.0              -         -\n",
            "8    CMD_001      100008.0              -         -\n",
            "9    CMD_009      100009.0              -         -\n",
            "10   CMD_002      100010.0              -         -\n",
            "11   CMD_010      100011.0              -         -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(master_records.head(10).fillna('-') )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWv7fj9HUFYZ",
        "outputId": "178fa899-68f8-4d61-8f72-678f8ccda98a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Master_ID     S1_ID   S2_ID      S3_ID\n",
            "0   CMD_001  100008.0  CL-009  CUST-1008\n",
            "1   CMD_002  100010.0  CL-011  CUST-1010\n",
            "2   CMD_003  100002.0  CL-003  CUST-1002\n",
            "3   CMD_004  100004.0  CL-005  CUST-1004\n",
            "4   CMD_005  100003.0  CL-004  CUST-1003\n",
            "5   CMD_006  100000.0  CL-001  CUST-1000\n",
            "6   CMD_007  100007.0  CL-008  CUST-1007\n",
            "7   CMD_008  100005.0  CL-006  CUST-1005\n",
            "8   CMD_009  100009.0  CL-010  CUST-1009\n",
            "9   CMD_010  100011.0       -          -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================\n",
        "# --- 5. Survivorship and Golden Record Creation Script (Recency Rule) ---\n",
        "# ====================================================================================\n",
        "\n",
        "# Note: This script assumes 'staged_df' has been updated with the 'Master_ID' column\n",
        "# from the execution of the Step 4 script.\n",
        "\n",
        "# Define the canonical source columns whose values will be used for survivorship\n",
        "# Corrected to use standardized column names from staged_df\n",
        "SOURCE_VALUE_COLS = ['FirstName_S', 'LastName_S', 'DOB', 'Sex_S', 'Address_S', 'Phone_S']\n",
        "\n",
        "# Helper function for Recency Survivorship (Accesses the canonical source value)\n",
        "def get_most_recent_value(series, full_df):\n",
        "    \"\"\"\n",
        "    Retrieves the attribute value corresponding to the maximum CreationDate\n",
        "    for the group of records.\n",
        "    \"\"\"\n",
        "    # 1. Get the indices of the records in the current group\n",
        "    group_indices = series.index\n",
        "\n",
        "    # 2. Access the CreationDate column for these specific records\n",
        "    creation_dates = full_df.loc[group_indices]['CreationDate']\n",
        "\n",
        "    # 3. Find the index corresponding to the latest non-missing CreationDate\n",
        "    if creation_dates.dropna().empty:\n",
        "        # Fallback: if all dates are NaT, just return the first non-NaN value\n",
        "        return series.iloc[0] if not series.dropna().empty else None\n",
        "\n",
        "    best_record_index = creation_dates.dropna().idxmax()\n",
        "\n",
        "    # 4. Return the attribute value from the winning record\n",
        "    # Access the value from the correct standardized column\n",
        "    return full_df.loc[best_record_index][series.name]\n",
        "\n",
        "\n",
        "# 1. Aggregate to the Master_ID level using the robust .agg() method\n",
        "# This step creates the Golden Record (Master_* attributes) and the full X-Ref\n",
        "master_data = staged_df.groupby('Master_ID', dropna=False).agg(\n",
        "\n",
        "    # X-Ref Aggregation: Concatenate all linked source IDs\n",
        "    S1_ID=('S1_Policy_ID', lambda x: ', '.join(x.dropna().astype(str).unique())),\n",
        "    S2_ID=('S2_Claimant_ID', lambda x: ', '.join(x.dropna().astype(str).unique())),\n",
        "    S3_ID=('S3_CRM_ID', lambda x: ', '.join(x.dropna().astype(str).unique())),\n",
        "\n",
        "    # Golden Record Attributes: Apply Recency Survivorship on standardized attributes\n",
        "    Master_FirstName=('FirstName_S', lambda x: get_most_recent_value(x, staged_df)),\n",
        "    Master_LastName=('LastName_S', lambda x: get_most_recent_value(x, staged_df)),\n",
        "    Master_DOB=('DOB', lambda x: get_most_recent_value(x, staged_df)),\n",
        "    Master_Sex=('Sex_S', lambda x: get_most_recent_value(x, staged_df)),\n",
        "    Master_Address=('Address_S', lambda x: get_most_recent_value(x, staged_df)),\n",
        "    Master_Phone=('Phone_S', lambda x: get_most_recent_value(x, staged_df)),\n",
        ").reset_index()\n",
        "\n",
        "\n",
        "# 2. Final Clean-up and Display Formatting\n",
        "final_result_df = master_data.copy()\n",
        "\n",
        "# Replace empty ID strings with '-' for clean output\n",
        "final_result_df['S1_ID'] = final_result_df['S1_ID'].replace('', '-')\n",
        "final_result_df['S2_ID'] = final_result_df['S2_ID'].replace('', '-')\n",
        "final_result_df['S3_ID'] = final_result_df['S3_ID'].replace('', '-')\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"--- Step 5: FINAL GOLDEN RECORD & CROSS-REFERENCE TABLE (X-Ref) ---\")\n",
        "print(\"Golden Record attributes determined by **Most Recent CreationDate** rule.\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Select and rename columns for the comprehensive final output\n",
        "final_display_cols = [\n",
        "    'Master_ID',\n",
        "    'Master_FirstName', 'Master_LastName', 'Master_DOB', 'Master_Sex',\n",
        "    'Master_Address', 'Master_Phone',\n",
        "    'S1_ID', 'S2_ID', 'S3_ID'\n",
        "]\n",
        "\n",
        "print(final_result_df[final_display_cols].rename(columns={\n",
        "    'S1_ID': 'Source 1 ID (Life)',\n",
        "    'S2_ID': 'Source 2 ID (Claims)',\n",
        "    'S3_ID': 'Source 3 ID (CRM)'\n",
        "}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpQTvkX_TkVp",
        "outputId": "5cc425b8-6a47-46fb-d399-2a06b1d09aa9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "--- Step 5: FINAL GOLDEN RECORD & CROSS-REFERENCE TABLE (X-Ref) ---\n",
            "Golden Record attributes determined by **Most Recent CreationDate** rule.\n",
            "================================================================================\n",
            "   Master_ID Master_FirstName Master_LastName  Master_DOB Master_Sex  \\\n",
            "0    CMD_001            ALICE           BROWN  1995-01-01     FEMALE   \n",
            "1    CMD_002            CHRIS           GREEN  2000-03-10       MALE   \n",
            "2    CMD_003              J J           SMYTH  1985-05-15       MALE   \n",
            "3    CMD_004            JAINE             DOH  1990-11-20     FEMALE   \n",
            "4    CMD_005             JANE             DOE  1990-11-20     FEMALE   \n",
            "5    CMD_006              JON           SMITH  1985-05-15       MALE   \n",
            "6    CMD_007             MARY        WILLIAMS  1988-08-08     FEMALE   \n",
            "7    CMD_008            PETER           JONES  1975-02-01       MALE   \n",
            "8    CMD_009           ROBERT           WHITE  1970-12-25       MALE   \n",
            "9    CMD_010             MARK           BAKER  2004-04-17       MALE   \n",
            "10   CMD_011            DAVID          TAYLOR  1990-12-13       MALE   \n",
            "11   CMD_012             MARK           BAKER  1974-10-16     FEMALE   \n",
            "12   CMD_013            LAURA          TAYLOR  2004-07-17     FEMALE   \n",
            "13   CMD_014            LAURA           BAKER  1992-10-26       MALE   \n",
            "14   CMD_015            LAURA           CLARK  1989-02-19       MALE   \n",
            "15   CMD_016             MARK            HALL  1985-02-27     FEMALE   \n",
            "16   CMD_017            LAURA            HALL  1998-06-03     FEMALE   \n",
            "17   CMD_018            SARAH           BAKER  2002-06-19       MALE   \n",
            "18   CMD_019            DAVID           BAKER  1973-03-25     FEMALE   \n",
            "19   CMD_020            SARAH           CLARK  1995-11-08     FEMALE   \n",
            "20   CMD_021            LAURA           CLARK  1996-02-16       MALE   \n",
            "21   CMD_022            SARAH           CLARK  1994-11-19     FEMALE   \n",
            "22   CMD_023             MARK           BAKER  2003-11-13     FEMALE   \n",
            "23   CMD_024            SARAH          TAYLOR  1983-04-19       MALE   \n",
            "24   CMD_025            LAURA          TAYLOR  1993-05-06     FEMALE   \n",
            "25   CMD_026            DAVID          TAYLOR  2001-01-01       MALE   \n",
            "26   CMD_027            DAVID           BAKER  2001-02-05     FEMALE   \n",
            "27   CMD_028             MARK           CLARK  1982-01-07     FEMALE   \n",
            "28   CMD_029             MARK          TAYLOR  1984-06-11       MALE   \n",
            "29   CMD_030            DAVID           CLARK  2005-04-10     FEMALE   \n",
            "30   CMD_031            DAVID            HALL  1992-08-04     FEMALE   \n",
            "31   CMD_032            DAVID            HALL  2004-04-14       MALE   \n",
            "32   CMD_033            DAVID           BAKER  1990-03-03       MALE   \n",
            "33   CMD_034             MARK          TAYLOR  2002-01-20       MALE   \n",
            "34   CMD_035            DAVID           BAKER  1979-07-04     FEMALE   \n",
            "35   CMD_036            LAURA           CLARK  1979-11-06       MALE   \n",
            "\n",
            "        Master_Address Master_Phone  Source 1 ID (Life) Source 2 ID (Claims)  \\\n",
            "0           50 HIGH ST         None            100008.0               CL-009   \n",
            "1          90 PARK AVE         None            100010.0               CL-011   \n",
            "2   123 MAIN ST APT 2B         None            100002.0               CL-003   \n",
            "3           45 OAK AVE         None            100004.0               CL-005   \n",
            "4     45 OAK AVE, CITY         None            100003.0               CL-004   \n",
            "5      123 MAIN STREET         None  100000.0, 100001.0       CL-001, CL-002   \n",
            "6          33 RIVER RD         None            100007.0               CL-008   \n",
            "7          789 PINE LN         None  100005.0, 100006.0       CL-006, CL-007   \n",
            "8            10 ELM DR         None            100009.0               CL-010   \n",
            "9        280 RANDOM RD         None            100011.0                    -   \n",
            "10       131 RANDOM RD         None            100012.0                    -   \n",
            "11       109 RANDOM RD         None            100013.0                    -   \n",
            "12       353 RANDOM RD         None            100014.0                    -   \n",
            "13       286 RANDOM RD         None            100015.0                    -   \n",
            "14       757 RANDOM RD         None            100016.0                    -   \n",
            "15       485 RANDOM RD         None            100017.0                    -   \n",
            "16       572 RANDOM RD         None            100018.0                    -   \n",
            "17       140 RANDOM RD         None            100019.0                    -   \n",
            "18        44 RANDOM RD         None                   -               CL-012   \n",
            "19       397 RANDOM RD         None                   -               CL-013   \n",
            "20       831 RANDOM RD         None                   -               CL-014   \n",
            "21       967 RANDOM RD         None                   -               CL-015   \n",
            "22       711 RANDOM RD         None                   -               CL-016   \n",
            "23       888 RANDOM RD         None                   -               CL-017   \n",
            "24       197 RANDOM RD         None                   -               CL-018   \n",
            "25       822 RANDOM RD         None                   -               CL-019   \n",
            "26       657 RANDOM RD         None                   -               CL-020   \n",
            "27       108 RANDOM RD         None                   -                    -   \n",
            "28       471 RANDOM RD         None                   -                    -   \n",
            "29       776 RANDOM RD         None                   -                    -   \n",
            "30       867 RANDOM RD         None                   -                    -   \n",
            "31       752 RANDOM RD         None                   -                    -   \n",
            "32       743 RANDOM RD         None                   -                    -   \n",
            "33       180 RANDOM RD         None                   -                    -   \n",
            "34       252 RANDOM RD         None                   -                    -   \n",
            "35       962 RANDOM RD         None                   -                    -   \n",
            "\n",
            "       Source 3 ID (CRM)  \n",
            "0              CUST-1008  \n",
            "1              CUST-1010  \n",
            "2              CUST-1002  \n",
            "3              CUST-1004  \n",
            "4              CUST-1003  \n",
            "5   CUST-1000, CUST-1001  \n",
            "6              CUST-1007  \n",
            "7   CUST-1005, CUST-1006  \n",
            "8              CUST-1009  \n",
            "9                      -  \n",
            "10                     -  \n",
            "11                     -  \n",
            "12                     -  \n",
            "13                     -  \n",
            "14                     -  \n",
            "15                     -  \n",
            "16                     -  \n",
            "17                     -  \n",
            "18                     -  \n",
            "19                     -  \n",
            "20                     -  \n",
            "21                     -  \n",
            "22                     -  \n",
            "23                     -  \n",
            "24                     -  \n",
            "25                     -  \n",
            "26                     -  \n",
            "27             CUST-1011  \n",
            "28             CUST-1012  \n",
            "29             CUST-1013  \n",
            "30             CUST-1014  \n",
            "31             CUST-1015  \n",
            "32             CUST-1016  \n",
            "33             CUST-1017  \n",
            "34             CUST-1018  \n",
            "35             CUST-1019  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 6. ID Lookup Script (Simulating Data Syndication)\n",
        "\n",
        "import pandas as pd # Ensure pandas is imported if this is run independently\n",
        "\n",
        "def lookup_source_ids_by_master_id(master_id: str, x_ref_df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Simulates an API call to the MDM Hub to retrieve all linked source IDs\n",
        "     and the Golden Record attributes for a given Master ID, printing the IDs\n",
        "     as part of the main output block.\n",
        "\n",
        "    Returns a dictionary including the Master ID and all found source IDs.\n",
        "    \"\"\"\n",
        "    if master_id not in x_ref_df['Master_ID'].values:\n",
        "        print(f\"\\n❌ ERROR: Master ID '{master_id}' not found.\")\n",
        "        return None\n",
        "\n",
        "    # Get the row corresponding to the Master ID\n",
        "    result = x_ref_df[x_ref_df['Master_ID'] == master_id].iloc[0]\n",
        "\n",
        "    # --- Prepare Linked Source IDs ---\n",
        "    available_ids = {\n",
        "        'Source 1 ID (Life)': result.get('S1_ID', '-'),\n",
        "        'Source 2 ID (Claims)': result.get('S2_ID', '-'),\n",
        "        'Source 3 ID (CRM)': result.get('S3_ID', '-')\n",
        "    }\n",
        "    found_ids = {}\n",
        "\n",
        "    # Collect found IDs and format them for printing/return\n",
        "    for source, source_id in available_ids.items():\n",
        "        if source_id != '-' and pd.notna(source_id) and source_id != '':\n",
        "            found_ids[source] = source_id\n",
        "\n",
        "    # --- Print Consolidated Lookup Result ---\n",
        "    print(f\"\\n--- Lookup Result for Master ID: {master_id} ---\")\n",
        "\n",
        "    # Golden Record Attributes (Consolidated Print)\n",
        "    print(\"\\n✅ Golden Record Attributes & X-Reference:\")\n",
        "\n",
        "    # PII/Golden Attributes\n",
        "    print(f\"  - First Name: {result.get('Master_FirstName', '-')}\")\n",
        "    print(f\"  - Last Name: {result.get('Master_LastName', '-')}\")\n",
        "    print(f\"  - DOB: {result.get('Master_DOB', '-')}\")\n",
        "    print(f\"  - Address: {result.get('Master_Address', '-')}\")\n",
        "    print(f\"  - Phone: {result.get('Master_Phone', '-')}\")\n",
        "\n",
        "    # Source IDs (Printed immediately after PII)\n",
        "    for source, source_id in found_ids.items():\n",
        "        print(f\"  - {source}: {source_id}\")\n",
        "\n",
        "    # --- Return the Master ID and the found source IDs (No Change to Return) ---\n",
        "    return {\n",
        "        'Master_ID': master_id,\n",
        "        'Linked_Source_IDs': found_ids\n",
        "    }"
      ],
      "metadata": {
        "id": "Q2iCkHwSXMx-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example Lookup 1: A customer with records in multiple sources (John Smith Group) ---\n",
        "# Master ID 100 links John/Jon/J.J. Smith records from S1, S2, and S3\n",
        "lookup_source_ids_by_master_id('CMD_001', final_result_df)\n",
        "\n",
        "# --- Example Lookup 2: A customer with a record in only one source (Unique record) ---\n",
        "# Robert White is usually assigned Master ID 107 (check your output if running the full script)\n",
        "# We'll pick an ID that only links to one system, e.g., Alice Brown (usually MID-103)\n",
        "lookup_source_ids_by_master_id('CMD_003', final_result_df)\n",
        "\n",
        "# --- Example Lookup 3: A non-existent ID ---\n",
        "lookup_source_ids_by_master_id('CMD_109', final_result_df)\n",
        "\n",
        "# --- Example Lookup 4: A non-existent ID ---\n",
        "lookup_source_ids_by_master_id('CMD_010', final_result_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvMz2OG2XOO3",
        "outputId": "20cdacbe-6ac3-4eae-ef17-8b5a5824c4dc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Lookup Result for Master ID: CMD_001 ---\n",
            "\n",
            "✅ Golden Record Attributes & X-Reference:\n",
            "  - First Name: ALICE\n",
            "  - Last Name: BROWN\n",
            "  - DOB: 1995-01-01\n",
            "  - Address: 50 HIGH ST\n",
            "  - Phone: None\n",
            "  - Source 1 ID (Life): 100008.0\n",
            "  - Source 2 ID (Claims): CL-009\n",
            "  - Source 3 ID (CRM): CUST-1008\n",
            "\n",
            "--- Lookup Result for Master ID: CMD_003 ---\n",
            "\n",
            "✅ Golden Record Attributes & X-Reference:\n",
            "  - First Name: J J\n",
            "  - Last Name: SMYTH\n",
            "  - DOB: 1985-05-15\n",
            "  - Address: 123 MAIN ST APT 2B\n",
            "  - Phone: None\n",
            "  - Source 1 ID (Life): 100002.0\n",
            "  - Source 2 ID (Claims): CL-003\n",
            "  - Source 3 ID (CRM): CUST-1002\n",
            "\n",
            "❌ ERROR: Master ID 'CMD_109' not found.\n",
            "\n",
            "--- Lookup Result for Master ID: CMD_010 ---\n",
            "\n",
            "✅ Golden Record Attributes & X-Reference:\n",
            "  - First Name: MARK\n",
            "  - Last Name: BAKER\n",
            "  - DOB: 2004-04-17\n",
            "  - Address: 280 RANDOM RD\n",
            "  - Phone: None\n",
            "  - Source 1 ID (Life): 100011.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Master_ID': 'CMD_010',\n",
              " 'Linked_Source_IDs': {'Source 1 ID (Life)': '100011.0'}}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_result_df.head(10).fillna('-') )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MLbmEG7Zi_f",
        "outputId": "59dce151-efa0-4e1f-9250-f7145daf1eca"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Master_ID               S1_ID           S2_ID                 S3_ID  \\\n",
            "0   CMD_001            100008.0          CL-009             CUST-1008   \n",
            "1   CMD_002            100010.0          CL-011             CUST-1010   \n",
            "2   CMD_003            100002.0          CL-003             CUST-1002   \n",
            "3   CMD_004            100004.0          CL-005             CUST-1004   \n",
            "4   CMD_005            100003.0          CL-004             CUST-1003   \n",
            "5   CMD_006  100000.0, 100001.0  CL-001, CL-002  CUST-1000, CUST-1001   \n",
            "6   CMD_007            100007.0          CL-008             CUST-1007   \n",
            "7   CMD_008  100005.0, 100006.0  CL-006, CL-007  CUST-1005, CUST-1006   \n",
            "8   CMD_009            100009.0          CL-010             CUST-1009   \n",
            "9   CMD_010            100011.0               -                     -   \n",
            "\n",
            "  Master_FirstName Master_LastName  Master_DOB Master_Sex      Master_Address  \\\n",
            "0            ALICE           BROWN  1995-01-01     FEMALE          50 HIGH ST   \n",
            "1            CHRIS           GREEN  2000-03-10       MALE         90 PARK AVE   \n",
            "2              J J           SMYTH  1985-05-15       MALE  123 MAIN ST APT 2B   \n",
            "3            JAINE             DOH  1990-11-20     FEMALE          45 OAK AVE   \n",
            "4             JANE             DOE  1990-11-20     FEMALE    45 OAK AVE, CITY   \n",
            "5              JON           SMITH  1985-05-15       MALE     123 MAIN STREET   \n",
            "6             MARY        WILLIAMS  1988-08-08     FEMALE         33 RIVER RD   \n",
            "7            PETER           JONES  1975-02-01       MALE         789 PINE LN   \n",
            "8           ROBERT           WHITE  1970-12-25       MALE           10 ELM DR   \n",
            "9             MARK           BAKER  2004-04-17       MALE       280 RANDOM RD   \n",
            "\n",
            "  Master_Phone  \n",
            "0            -  \n",
            "1            -  \n",
            "2            -  \n",
            "3            -  \n",
            "4            -  \n",
            "5            -  \n",
            "6            -  \n",
            "7            -  \n",
            "8            -  \n",
            "9            -  \n"
          ]
        }
      ]
    }
  ]
}